\documentclass[main.tex]{subfiles}
\begin{document}
\thispagestyle{plain}
\chapter*{Conclusions}
\markboth{CONCLUSIONS}{}
\addcontentsline{toc}{chapter}{Conclusions}

This thesis presents a search for Higgs boson pair production via gluon fusion (ggF) and vector boson fusion (VBF) in the channel where one of the Higgs bosons decays into two $\tau$ leptons and the other Higgs decays into two b quarks (\hhbbtt{}). This process is predicted by the Standard Model (SM), but could be affected by Beyond the Standard Model (BSM) effects. The search is performed using proton-proton collision data at $\sqrt{s}=13$~TeV collected by the CMS experiment in the LHC during 2016, 2017, and 2018, equivalent to 138~fb${}^{-1}$. The analysed final state is where two b quarks and two $\tau$ leptons are produced. The three decay modes of the $\tau\tau$ pair with the largest branching ratio have been studied, requiring one $\tau$ to decay into hadrons and the other leptonically or hadronically.

This analysis has been based on the previously published \hhbbtt{} search, performed only with 2016 data. Many improvements have been included since, both in object reconstruction and identification (e.g. DeepJet and DeepTau algorithms for the identification of b jets and $\tau$ leptons decaying into hadrons) and at analysis level. A new categorization scheme has been studied focused on the VBF production mode, in order to assign events to categories associated enriched in events belonging to the VBF, ggF, and the main background processes. This categorization is performed using a multi-class deep neural network (DNN), providing more sensitivity to the VBF analysis thanks to the additional discrimination and the ability to constrain nuisance parameters. A complete study of the main backgrounds has been performed, focusing on the QCD background estimation. Several validity tests have been done to study the method used for QCD estimation, with satisfactory results.

Signal extraction is performed with a binned maximum likelihood fit to another DNN that discriminates between signal- and background-like events. Upper limits at 95\% confidence level (CL) are set considering as signal HH produced via ggF and VBF (inclusive results) or produced by only VBF (fixing the ggF cross section to its SM prediction). The observed (expected) 95\% CL upper limit on inclusive HH production cross section corresponds to 3.3 (5.2) times the theoretical cross section predicted by the SM, the second most sensitive result among all CMS HH analyses. For VBF-only production, this limit is set at 124 (154) times the theoretical prediction, which is the best result among all CMS and ATLAS HH analyses. Additionally, 95\% CL constraints can be set to the Higgs self-coupling and its coupling to the vector bosons. Deviations of these couplings from their SM predictions could be produced by BSM effects, so it is really important to try to constrain their values. For $\kappa_\lambda$, the Higgs self-coupling modifier, the observed (expected) constraint has been set to $-1.7 < \kappa_\lambda < 8.7$ ($-2.9 < \kappa_\lambda < 9.8$). For $\kappa_{2V}$, the modifier for the coupling between two Higgs bosons and two vector bosons, the obtained constraint was $-0.4 < \kappa_{2V} < 2.6$ ($-0.6 < \kappa_{2V} < 2.8$). Looking into the future, projections for Run 3 provide an expected upper limit on the inclusive HH cross section of 3.2 times the SM prediction, while for HL-LHC this limit is expected to drop to 1.4 times the SM prediction. 

For the new data taking period (Run 3, 2022-2025), a new trigger strategy has been studied, focusing on the $\tau\tau$ decay mode where both $\tau$ decay hadronically. This new strategy consists of including in the L1 and HLT menus a trigger that requires two \tauh{} and one jet, where the $p_T$ threshold on the \tauh{} is smaller than the one from the double-$\tau_h$ triggers, already present in the Run 2 menus. The goal of this strategy is to increase the acceptance gain on the \htt{} and \hhbbtt{} analyses by lowering the $\tau$ $p_T$ threshold. A complete optimization was performed in order to obtain the online $\tau$ and jet $p_T$ thresholds of a new L1 seed to be included in the menu, having a compromise between the acceptance gained and the rate added. Once the L1 seed was implemented, its corresponding HLT path was also developed. The L1 seed and HLT path were included prior to the 2022 data taking period, so its performance can be studied using real data and simulation. The rate added was in agreement with the expectations obtained with 2018 zero bias data. The efficiencies from both \tauh{} and jet objects have also been studied, with a good agreement between data and simulation. A first test has been performed to compute the sensitivity gain in the \hhbbtt{} analysis when considering the new trigger strategy (logical OR of the double-\tauh{} and the double-\tauh{} plus jet triggers instead of just the double-\tauh{} trigger). When only applying the $\tau\tau$ pair selection (both at trigger and offline level) and a minimal jet requirement if the event satisfied the double-$\tau_h$ plus jet trigger selection, 6\% and 9\% sensitivity gains were obtained for the HH ggF and HH VBF samples, respectively.

Finally, the Analytical Method algorithm for muon trigger primitive generation in Phase-2 has been presented. A thorough description of the algorithm has been included. The algorithm has been validated with a simulated sample assuming the worst expected conditions, showing excellent performance both in efficiency and resolution. The agreement between the software emulator and the firmware implementation has been studied using a dedicated setup in the laboratory, obtaining a matching between both implementations above 98\% when all qualities are considered, and almost 100\% for very high quality trigger primitives. When performing a fit with the same hits and laterality combinations, the trigger primitive parameters (time, position, and direction) match between both implementations to the least significant bit. The hardware implementation (from the previous algorithm version) has been tested with collision data at CMS, providing very good results in efficiency, time resolution, and matching with the offline reconstructed segments. It is expected that the latest firmware version will be deployed inside the CMS infrastructure in the upcoming months, showing the significant improvement in performance the CMS DT trigger will experience during HL-LHC.





\end{document}
